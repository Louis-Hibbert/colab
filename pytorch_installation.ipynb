{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_installation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTRBnW6QSc86nFfyRkuDHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Louis-Hibbert/colab/blob/main/pytorch_installation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53khjOmsvdNk",
        "outputId": "ba9ad131-6c11-44e0-a491-877d08dcfe01"
      },
      "source": [
        "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3MB)\n",
            "\u001b[K     |█████████████                   | 834.1MB 2.1MB/s eta 0:09:46tcmalloc: large alloc 1147494400 bytes == 0x55de36cda000 @  0x7f88b1a5a615 0x55ddfd7a4cdc 0x55ddfd88452a 0x55ddfd7a7afd 0x55ddfd898fed 0x55ddfd81b988 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81b7f0 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81832a 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd91c3e1 0x55ddfd87c6a9 0x55ddfd7e7cc4 0x55ddfd7a8559 0x55ddfd81c4f8 0x55ddfd7a930a 0x55ddfd8173b5 0x55ddfd8167ad 0x55ddfd7a93ea 0x55ddfd8173b5 0x55ddfd7a930a 0x55ddfd8173b5\n",
            "\u001b[K     |████████████████▌               | 1055.7MB 57.9MB/s eta 0:00:18tcmalloc: large alloc 1434370048 bytes == 0x55de7b330000 @  0x7f88b1a5a615 0x55ddfd7a4cdc 0x55ddfd88452a 0x55ddfd7a7afd 0x55ddfd898fed 0x55ddfd81b988 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81b7f0 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81832a 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd91c3e1 0x55ddfd87c6a9 0x55ddfd7e7cc4 0x55ddfd7a8559 0x55ddfd81c4f8 0x55ddfd7a930a 0x55ddfd8173b5 0x55ddfd8167ad 0x55ddfd7a93ea 0x55ddfd8173b5 0x55ddfd7a930a 0x55ddfd8173b5\n",
            "\u001b[K     |█████████████████████           | 1336.2MB 34.3MB/s eta 0:00:21tcmalloc: large alloc 1792966656 bytes == 0x55de00162000 @  0x7f88b1a5a615 0x55ddfd7a4cdc 0x55ddfd88452a 0x55ddfd7a7afd 0x55ddfd898fed 0x55ddfd81b988 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81b7f0 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81832a 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd91c3e1 0x55ddfd87c6a9 0x55ddfd7e7cc4 0x55ddfd7a8559 0x55ddfd81c4f8 0x55ddfd7a930a 0x55ddfd8173b5 0x55ddfd8167ad 0x55ddfd7a93ea 0x55ddfd8173b5 0x55ddfd7a930a 0x55ddfd8173b5\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1MB 1.6MB/s eta 0:03:42tcmalloc: large alloc 2241208320 bytes == 0x55de6af4a000 @  0x7f88b1a5a615 0x55ddfd7a4cdc 0x55ddfd88452a 0x55ddfd7a7afd 0x55ddfd898fed 0x55ddfd81b988 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81b7f0 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81832a 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd817853 0x55ddfd899e36 0x55ddfd91c3e1 0x55ddfd87c6a9 0x55ddfd7e7cc4 0x55ddfd7a8559 0x55ddfd81c4f8 0x55ddfd7a930a 0x55ddfd8173b5 0x55ddfd8167ad 0x55ddfd7a93ea 0x55ddfd8173b5 0x55ddfd7a930a 0x55ddfd8173b5\n",
            "\u001b[K     |████████████████████████████████| 2041.3MB 1.4MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0x55def08ac000 @  0x7f88b1a591e7 0x55ddfd7daf37 0x55ddfd7a4cdc 0x55ddfd88452a 0x55ddfd7a7afd 0x55ddfd898fed 0x55ddfd81b988 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd7a930a 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81832a 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81832a 0x55ddfd8164ae\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x55dfde832000 @  0x7f88b1a5a615 0x55ddfd7a4cdc 0x55ddfd88452a 0x55ddfd7a7afd 0x55ddfd898fed 0x55ddfd81b988 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81760e 0x55ddfd7a930a 0x55ddfd81760e 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81832a 0x55ddfd8164ae 0x55ddfd7a93ea 0x55ddfd81832a 0x55ddfd8164ae 0x55ddfd7a9a81\n",
            "\u001b[K     |████████████████████████████████| 2041.3MB 3.5kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2MB 2.0MB/s \n",
            "\u001b[?25hCollecting torchaudio===0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/20/eab40caad8f4b97f5e91a5de8ba5ec29115e08fa4c9a808725490b7b4844/torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 13.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.19.5)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uet25S152rEO",
        "outputId": "9904a5dd-d190-4f52-c74b-cab800633c5b"
      },
      "source": [
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6211, 0.3713, 0.3706],\n",
            "        [0.3884, 0.9113, 0.3511],\n",
            "        [0.5713, 0.6205, 0.9483],\n",
            "        [0.1591, 0.9141, 0.8348],\n",
            "        [0.2130, 0.5290, 0.1095]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNDCwDNM3MiV",
        "outputId": "e09e3b67-e2af-447f-8a1a-5925afed2f63"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXuVMdXjnVzN",
        "outputId": "1ad455a2-7173-47e9-d9f3-8f88d879c193"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 22 02:47:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}